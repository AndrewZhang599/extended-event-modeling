{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide-input": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      require([], function() {\n",
       "      })\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "\tif (!js_urls.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\", \"https://unpkg.com/@holoviz/panel@^0.10.2/dist/panel.min.js\"];\n",
       "  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/widgets.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      require([], function() {\n      })\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n\tif (!js_urls.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\", \"https://unpkg.com/@holoviz/panel@^0.10.2/dist/panel.min.js\"];\n  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.10.2/dist/css/widgets.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## %cd /Users/bezdek/Box/DCL_ARCHIVE/Documents/Events/exp148_Corpus/viz\n",
    "\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For panel visualizations:\n",
    "import panel as pn\n",
    "#import param\n",
    "# For displaying images:\n",
    "import cv2\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from copy import deepcopy\n",
    "#from run_sem_with_features import preprocess_skel\n",
    "import joblib\n",
    "from utils import get_point_biserial, get_binned_prediction\n",
    "import scipy.stats as stats\n",
    "\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Variables and Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: to add another global variable, need to init, add to global term, and define an update based on run\n",
    "# TODO: download new inputdf, diagnostic, gt_freqs and change below variables to visualize.\n",
    "\n",
    "title = '# Visualize Input Features'\n",
    "tag = 'mar_20_individual_depth_scene'\n",
    "default_run = '1.1.1'\n",
    "epoch = '_0'\n",
    "# epoch = ''\n",
    "\n",
    "# Load sample input dfs:\n",
    "runs = glob('output/skel/*_kinect_skel_features.csv')\n",
    "runs = [os.path.basename(x).split('_')[0] for x in runs]\n",
    "run_select = pn.widgets.Select(name='Select Run', options=runs, value=f'{default_run}')\n",
    "skel_checkbox = pn.widgets.Checkbox(name='Display Skeleton?')\n",
    "obj_checkbox = pn.widgets.Checkbox(name='Display Nearest Objects?')\n",
    "z_checkbox = pn.widgets.Checkbox(name='Z-score time courses?')\n",
    "# Options and values for these widgets are just placeholders, will be updated based on run by listen_to_run \n",
    "frame_slider = pn.widgets.DiscreteSlider(name='Select Frame', options=list([0, 1, 2, 3]), value=0)\n",
    "text_input = pn.widgets.TextInput(name='Second', placeholder='Enter timepoint (in second)')\n",
    "second_slider = pn.widgets.DiscreteSlider(name='Select Second', options=list([0, 1, 2, 3]), value=0)\n",
    "tc_feature_select = pn.widgets.MultiSelect(name='Select Time Course Features', value=['features[3]', 'features[4]'], options=['features[3]','features[4]'], size=8)\n",
    "pair_feature_select = pn.widgets.MultiSelect(name='Select 2 or 3 Features for Comparison', value=['features[3]' ,'features[4]'],options=['features[3],features[4]'], size=8)\n",
    "\n",
    "\n",
    "second_interval = 1 # interval to group boundaries\n",
    "frame_per_second = 3 # sampling rate to input to SEM\n",
    "fps = 25.0 # kinect videos\n",
    "frame_interval = frame_per_second * second_interval\n",
    "\n",
    "# declare global variables that will be used for each individual runs (to save loading time)\n",
    "skel_df, appear_df, flow_df, objdf, objhand_df, anchored_frames, appear_df_post, flow_df_post, skel_df_post, gt_freqs, \\\n",
    "sem_readouts, inputdf, first_frame, offset, pca_input_df, pred_skel_df, skel_df_unscaled,categories, pred_objhand, word2vec, objdf_z = [None] * 21\n",
    "\n",
    "glove_vectors = pkl.load(open('gen_sim_glove_50.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking Widgets and Updating Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_to_frame(frame_slider, second):\n",
    "    frameid = int(float(second.new) * 25)\n",
    "    while frameid not in anchored_frames:\n",
    "        frameid += 1\n",
    "    frame_slider.value = frameid\n",
    "second_slider.link(frame_slider, callbacks={'value': second_to_frame})\n",
    "def text_to_secondsl(second_slider, text):\n",
    "    second = int(text.new)\n",
    "    second_slider.value = second\n",
    "text_input.link(second_slider, callbacks={'value': text_to_secondsl})\n",
    "\n",
    "@pn.depends(run_select.param.value)\n",
    "def listen_to_run(run_select):\n",
    "    global skel_df, appear_df, flow_df, objdf, objhand_df, anchored_frames, appear_df_post, flow_df_post, skel_df_post, \\\n",
    "        gt_freqs, sem_readouts, inputdf, first_frame, offset, pca_input_df, pred_skel_df, skel_df_unscaled,categories, pred_objhand, word2vec, objdf_z\n",
    "    # These are dataframes before processing (standardizing, interpolating, concatenating, dropna, resample)\n",
    "    skel_df=pd.read_csv(f'output/skel/{run_select}_kinect_skel_features.csv')\n",
    "    appear_df = pd.read_csv(f'output/appear/{run_select}_kinect_appear.csv')\n",
    "    flow_df=pd.read_csv(f'output/vid/{run_select}_kinect_video_features.csv')\n",
    "    # Caching frames to speed up interactive time\n",
    "#     anchored_frames = pkl.load(open(f'output/run_sem/{tag}/{run_select}_kinect_trimjan_09_333_less_boundaries_frames.pkl', 'rb'))\n",
    "    anchored_frames = joblib.load(f'output/run_sem/frames/{run_select}_kinect_trimjan_27_pca_frames.joblib')\n",
    "    # This data is for plotting diagnostic results\n",
    "    gt_freqs = pkl.load(open(f'output/run_sem/{tag}/{run_select}_kinect_trim{tag}_gtfreqs.pkl', 'rb'))\n",
    "    sem_readouts = pkl.load(open(f'output/run_sem/{tag}/{run_select}_kinect_trim{tag}_diagnostic{epoch}.pkl', 'rb'))\n",
    "    # Preprocess likelihoods because old_lik contains new likelihoods and repeat likelihoods as well\n",
    "    sem_readouts['frame_dynamics']['old_lik'] = [[l for l in all_lik if\n",
    "                                                  not(np.isclose(l, new_lik, rtol=1e-2) or np.isclose(l, repeat_lik, rtol=1e-2))]\n",
    "                                                 for all_lik, new_lik, repeat_lik in\n",
    "                                                 zip(sem_readouts['frame_dynamics']['old_lik'], sem_readouts['frame_dynamics']['new_lik'], sem_readouts['frame_dynamics']['repeat_lik'])]\n",
    "    sem_readouts['frame_dynamics']['old_lik']  = [l if len(l) else [-5000] for l in sem_readouts['frame_dynamics']['old_lik']]\n",
    "    sem_readouts['frame_dynamics']['old_prior'] = [[p for p in all_prior if\n",
    "                                              not(np.isclose(p, new_prior, rtol=1e-2) or np.isclose(p, repeat_prior, rtol=1e-2))]\n",
    "                                             for all_prior, new_prior, repeat_prior in\n",
    "                                             zip(sem_readouts['frame_dynamics']['old_prior'], sem_readouts['frame_dynamics']['new_prior'], sem_readouts['frame_dynamics']['repeat_prior'])]\n",
    "    sem_readouts['frame_dynamics']['old_prior']  = [p if len(p) else [-5000] for p in sem_readouts['frame_dynamics']['old_prior']]\n",
    "    # A list of dataframes after processing (appear->flow->skel->objhand). It also contains other dataframes for plotting (3 nearest_objects->object_coordinates)\n",
    "    # and x_train and x_inferred of SEM.\n",
    "    inputdf = pkl.load(open(f'output/run_sem/{tag}/{run_select}_kinect_trim{tag}_inputdf{epoch}.pkl', 'rb'))\n",
    "    # offset to align prediction boundaries with exact video timepoint\n",
    "    first_frame = inputdf[0].index[0]\n",
    "    offset = first_frame / fps / second_interval\n",
    "    \n",
    "    appear_df_post = inputdf[0]\n",
    "    flow_df_post = inputdf[1]\n",
    "    skel_df_post = inputdf[2]\n",
    "    objdf=inputdf[5]\n",
    "    # TODO: uncomment to test depth\n",
    "    objdf_z = inputdf[9]\n",
    "    objhand_df=inputdf[3]\n",
    "    \n",
    "    # Prepare dataframes to plot input skeleton and predicted skeleton\n",
    "    # skel_df_unscaled for sanity check, comparing to skel_df.\n",
    "    pca_input_df = inputdf[6]\n",
    "    pred_skel_df = inputdf[7]\n",
    "#     skel_df_unscaled = skel_df_post.copy().loc[:, skel_df_post.columns]\n",
    "    pred_skel_df = pred_skel_df.loc[:, skel_df_post.columns]\n",
    "    pca_input_df = pca_input_df.loc[:, skel_df_post.columns]\n",
    "\n",
    "#     skel_df_unscaled = skel_df_unscaled * skel_df.std() + skel_df.mean()\n",
    "    pred_skel_df = pred_skel_df * skel_df.std() + skel_df.mean()\n",
    "    pca_input_df = pca_input_df * skel_df.std() + skel_df.mean()\n",
    "\n",
    "#     skel_df_unscaled['frame'] = skel_df_unscaled.index\n",
    "    pred_skel_df['frame'] = pred_skel_df.index\n",
    "#     pca_input_df['frame'] = pca_input_df.index\n",
    "    pca_input_df.set_index(pred_skel_df.index, inplace=True)\n",
    "    pca_input_df['frame'] = pca_input_df.index # This is a workaround, will remove after new results come\n",
    "    for i in range(25):\n",
    "        new_column = f'J{i}_Tracked'\n",
    "#         skel_df_unscaled[new_column] = 'Inferred'\n",
    "        pred_skel_df[new_column] = 'Predicted'\n",
    "        pca_input_df[new_column] = 'Inferred'\n",
    "    # Add two new distances columns to objhand_df\n",
    "    # TODO: refactor so that it doesn't change the original dataframe\n",
    "    i=1\n",
    "    dists=[0]\n",
    "    euc_dists = [0]\n",
    "    while i < len(objhand_df):\n",
    "        dists.append(cosine(objhand_df.iloc[i],objhand_df.iloc[i-1]))\n",
    "        euc_dists.append(np.linalg.norm(objhand_df.iloc[i] - objhand_df.iloc[i-1]))\n",
    "        i+=1\n",
    "    objhand_df['cosine']=dists\n",
    "    objhand_df['euclid'] = euc_dists\n",
    "    # Prepare a dictionary of word2vec for this particular run\n",
    "    categories = set()\n",
    "    for c in inputdf[4].columns:\n",
    "        categories.update(inputdf[4].loc[:, c].dropna())\n",
    "    if None in categories:\n",
    "        categories.remove(None)\n",
    "\n",
    "    pred_objhand = inputdf[7]\n",
    "    pred_objhand = pred_objhand.loc[:, objhand_df.drop(['euclid', 'cosine'], axis=1, errors='ignore').columns]\n",
    "    word2vec = dict()\n",
    "    for category in categories:\n",
    "        r = np.zeros(shape=(1, pred_objhand.shape[1]))\n",
    "        try:\n",
    "            r += glove_vectors[category]\n",
    "        except Exception as e:\n",
    "            words = category.split(' ')\n",
    "            for w in words:\n",
    "                w = w.replace('(', '').replace(')', '')\n",
    "                r += glove_vectors[w]\n",
    "            r /= len(words)\n",
    "        word2vec[category] = r\n",
    "\n",
    "    # Update sliders\n",
    "    frame_slider.options = list(anchored_frames.keys())\n",
    "    frame_slider.value=list(anchored_frames.keys())[0]\n",
    "    second_slider.options=list(np.arange(inputdf[0].index[0] // fps, inputdf[0].index[-1] // fps))\n",
    "    second_slider.value=inputdf[0].index[0] // fps\n",
    "\n",
    "    features = skel_df_post.columns.tolist()\n",
    "    tc_feature_select.options = features\n",
    "    tc_feature_select.value = [features[3],features[4]]\n",
    "    pair_feature_select.options=features\n",
    "    pair_feature_select.value=[features[3],features[4]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appear Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pn.depends(frame_slider.param.value,run_select.param.value)\n",
    "def appear_plot(frame_slider,run_select): # start function\n",
    "    # appear_df = pd.read_csv('output/appear/'+run_select+'_kinect_appear.csv')\n",
    "    df = appear_df.reset_index()\n",
    "    fig,ax = plt.subplots()\n",
    "    df['second'] = df['frame'] / fps\n",
    "    df.plot(kind='line', x='second', y='appear', ax=ax)\n",
    "    df.plot(kind='line', x='second', y='disappear', ax=ax)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    plt.title('Appearances and Disappearances '+run_select)\n",
    "    #ax.get_legend().remove()\n",
    "    #plt.show()\n",
    "    # Plotting diagnostic embeded in a function\n",
    "    colors = {'new': 'red', 'old': 'green', 'restart': 'blue', 'repeat': 'purple'}\n",
    "    latest = 0\n",
    "    current = 0\n",
    "    # post = list(map(np.argmax, sem_readouts['frame_dynamics']['post']))\n",
    "    post = sem_readouts['e_hat']\n",
    "    switch = []\n",
    "    for i in post:\n",
    "        if i != current:\n",
    "            if i > latest:\n",
    "                switch.append('new_post')\n",
    "                latest = i\n",
    "            else:\n",
    "                switch.append('old_post')\n",
    "            current = i\n",
    "        else:\n",
    "            switch.append('current_post')\n",
    "    df = pd.DataFrame(switch, columns=['switch'], index=pred_objhand.index)\n",
    "    ax.vlines(df[df['switch'] == 'new_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to New '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['new'], linestyles='dotted')\n",
    "    ax.vlines(df[df['switch'] == 'old_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to Old '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['old'], linestyles='dotted')\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "@pn.depends(frame_slider.param.value,run_select.param.value)\n",
    "def appear_plot_post(frame_slider,run_select): # start function\n",
    "    # appear_df = pd.read_csv('output/appear/'+run_select+'_kinect_appear.csv')\n",
    "    df = appear_df_post.reset_index()\n",
    "    fig,ax = plt.subplots()\n",
    "    df['second'] = df['frame'] / fps\n",
    "    df.plot(kind='line', x='second', y='appear', ax=ax)\n",
    "    df.plot(kind='line', x='second', y='disappear', ax=ax)\n",
    "    ax.axvline(frame_slider,linewidth=3, color = 'r', alpha=0.5)\n",
    "    plt.title('Appearances and Disappearances Post'+run_select)\n",
    "    #ax.get_legend().remove()\n",
    "    #plt.show()\n",
    "    # Plotting diagnostic embeded in a function\n",
    "    colors = {'new': 'red', 'old': 'green', 'restart': 'blue', 'repeat': 'purple'}\n",
    "    latest = 0\n",
    "    current = 0\n",
    "    # post = list(map(np.argmax, sem_readouts['frame_dynamics']['post']))\n",
    "    post = sem_readouts['e_hat']\n",
    "    switch = []\n",
    "    for i in post:\n",
    "        if i != current:\n",
    "            if i > latest:\n",
    "                switch.append('new_post')\n",
    "                latest = i\n",
    "            else:\n",
    "                switch.append('old_post')\n",
    "            current = i\n",
    "        else:\n",
    "            switch.append('current_post')\n",
    "    df = pd.DataFrame(switch, columns=['switch'], index=pred_objhand.index)\n",
    "    ax.vlines(df[df['switch'] == 'new_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to New '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['new'], linestyles='dotted')\n",
    "    ax.vlines(df[df['switch'] == 'old_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to Old '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['old'], linestyles='dotted')\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pn.depends(tc_feature_select.param.value, frame_slider.param.value,z_checkbox.param.value,run_select.param.value)\n",
    "def time_plot(tc_feature_select,frame_slider,z_checkbox,run_select): # start function\n",
    "    skel_df['frame'] = (skel_df['sync_time'] * fps).apply(round).astype(int)\n",
    "    df = skel_df.reset_index()\n",
    "    if z_checkbox:\n",
    "        for feat in tc_feature_select:\n",
    "            df[feat] = (df[feat] - df[feat].mean())/df[feat].std(ddof=0)\n",
    "            #df[feat]=df[feat].apply(zscore)\n",
    "    fig,ax = plt.subplots()\n",
    "    df['second'] = df['frame'] / fps\n",
    "    for feat in tc_feature_select:\n",
    "        df.plot(kind='line', x='second', y=feat, alpha = 0.5,ax=ax)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    plt.title('Feature Time Course '+run_select)\n",
    "    #plt.show()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "@pn.depends(pair_feature_select.param.value, frame_slider.param.value,z_checkbox.param.value,run_select.param.value)\n",
    "def pair_plot(pair_feature_select,frame_slider,z_checkbox,run_select): # start function\n",
    "    skel_df['frame'] = (skel_df['sync_time'] * fps).apply(round).astype(int)\n",
    "    df = skel_df.reset_index()\n",
    "    if z_checkbox:\n",
    "        for feat in pair_feature_select:\n",
    "            df[feat] = (df[feat] - df[feat].mean())/df[feat].std(ddof=0)\n",
    "    pdf = df[df['frame'] == frame_slider]\n",
    "        \n",
    "    if len(pair_feature_select) == 2:\n",
    "        fig,ax = plt.subplots()\n",
    "        df.plot(kind='scatter', x=pair_feature_select[0], y=pair_feature_select[1],alpha=0.5,c=df['frame'],colormap='viridis',ax=ax)\n",
    "        ax.plot(pdf[pair_feature_select[0]],pdf[pair_feature_select[1]],marker='o',markersize=15,color='r',alpha=0.5)\n",
    "    elif len(pair_feature_select) == 3:\n",
    "        fig,ax=plt.subplots(subplot_kw=dict(projection='3d'))\n",
    "        p=ax.scatter(df[pair_feature_select[0]],df[pair_feature_select[1]],df[pair_feature_select[2]],c=df['frame'],cmap='viridis')\n",
    "        ax.plot(pdf[pair_feature_select[0]],pdf[pair_feature_select[1]],pdf[pair_feature_select[2]],marker='o',markersize=15,color='r')\n",
    "        ax.set_xlabel(pair_feature_select[0])\n",
    "        ax.set_ylabel(pair_feature_select[1])\n",
    "        ax.set_zlabel(pair_feature_select[2])\n",
    "\n",
    "        fig.colorbar(p)\n",
    "    else:\n",
    "        fig,ax = plt.subplots()\n",
    "    plt.title('Compare Features '+run_select)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "@pn.depends(frame_slider.param.value, run_select.param.value)\n",
    "def plot_reduced_features(frame_slider, run_select):\n",
    "\n",
    "    x_train = skel_df_post.to_numpy()\n",
    "    pca = PCA(n_components=2, whiten=True)\n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    df = pd.DataFrame(x_train, index=skel_df_post.index, columns=['pc_1', 'pc_2'])\n",
    "    fig, ax = plt.subplots()\n",
    "    df.plot(kind='scatter', x=df.columns[0], y=df.columns[1],alpha=0.5,c=df.index,colormap='viridis',ax=ax)\n",
    "    ax.plot(df.loc[frame_slider, 'pc_1'], df.loc[frame_slider, 'pc_2'], marker='o',markersize=15,color='r',alpha=0.5)\n",
    "    ax.set_title('Principal Components for Skeletons')\n",
    "    ax.axvline(frame_slider,linewidth=3, color = 'r', alpha=0.5)\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "@pn.depends(frame_slider.param.value, run_select.param.value)\n",
    "def skel_plot_post(frame_slider, run_select):\n",
    "\n",
    "    x_train = skel_df_post.to_numpy()\n",
    "    pca = PCA(n_components=0.9, whiten=True)\n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    change = [0]\n",
    "    for i in range(1, len(x_train)):\n",
    "        change.append(cosine(x_train[i], x_train[-1]))\n",
    "    df = pd.DataFrame(change, index=skel_df_post.index, columns=['feature_change'])\n",
    "    df = df.reset_index()\n",
    "    df['feature_change'] = gaussian_filter1d(df['feature_change'].values, 5)\n",
    "    fig, ax = plt.subplots()\n",
    "    df['second'] = df['frame'] / fps\n",
    "    df.plot(kind='line', x='second', y='feature_change',alpha=0.5,ax=ax)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    plt.title('Skel PCA Cosine Disntance '+run_select+ f'\\n{len(pca.explained_variance_)} components with {round(np.sum(pca.explained_variance_ratio_) * 100)}% variance')\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "@pn.depends(frame_slider.param.value, run_select.param.value)\n",
    "def skel_plot_post_euclid(frame_slider, run_select):\n",
    "\n",
    "    x_train = skel_df_post.to_numpy()\n",
    "    pca = PCA(n_components=0.9, whiten=True)\n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    change = [0]\n",
    "    for i in range(1, len(x_train)):\n",
    "        change.append(np.linalg.norm(x_train[i] - x_train[-1]) / x_train.shape[1])\n",
    "    df = pd.DataFrame(change, index=skel_df_post.index, columns=['feature_change'])\n",
    "    df = df.reset_index()\n",
    "    df['feature_change'] = gaussian_filter1d(df['feature_change'].values, 5)\n",
    "    fig, ax = plt.subplots()\n",
    "    df['second'] = df['frame'] / fps\n",
    "    df.plot(kind='line', x='second', y='feature_change',alpha=0.5,ax=ax)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    plt.title('Skel PCA Euclidean Distance '+run_select+ f'\\n{len(pca.explained_variance_)} components with {round(np.sum(pca.explained_variance_ratio_) * 100)}% variance')\n",
    "    # Plotting diagnostic embeded in a function\n",
    "    colors = {'new': 'red', 'old': 'green', 'restart': 'blue', 'repeat': 'purple'}\n",
    "    latest = 0\n",
    "    current = 0\n",
    "    # post = list(map(np.argmax, sem_readouts['frame_dynamics']['post']))\n",
    "    post = sem_readouts['e_hat']\n",
    "    switch = []\n",
    "    for i in post:\n",
    "        if i != current:\n",
    "            if i > latest:\n",
    "                switch.append('new_post')\n",
    "                latest = i\n",
    "            else:\n",
    "                switch.append('old_post')\n",
    "            current = i\n",
    "        else:\n",
    "            switch.append('current_post')\n",
    "    df = pd.DataFrame(switch, columns=['switch'], index=pred_objhand.index)\n",
    "    ax.vlines(df[df['switch'] == 'new_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to New '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['new'], linestyles='dotted')\n",
    "    ax.vlines(df[df['switch'] == 'old_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to Old '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['old'], linestyles='dotted')\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-Hand Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@pn.depends(frame_slider.param.value,run_select.param.value)\n",
    "def objhand_plot(frame_slider,run_select): # start function\n",
    "    x_train = objhand_df.drop(['cosine', 'euclid'], errors='ignore').to_numpy()\n",
    "    pca = PCA(n_components=0.9, whiten=True)\n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    change = [0]\n",
    "    for i in range(1, len(x_train)):\n",
    "        change.append(np.linalg.norm(x_train[i] - x_train[-1]) / x_train.shape[1])\n",
    "    df = pd.DataFrame(change, index=objhand_df.index, columns=['feature_change'])\n",
    "    df = df.reset_index()\n",
    "    df['feature_change'] = gaussian_filter1d(df['feature_change'].values, 5)\n",
    "    fig, ax = plt.subplots()\n",
    "    df['second'] = df['frame'] / fps\n",
    "    df.plot(kind='line', x='second', y='feature_change',alpha=0.5,ax=ax)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    plt.title('Objhand PCA Euclid Distance '+run_select+ f'\\n{len(pca.explained_variance_)} components with {round(np.sum(pca.explained_variance_ratio_) * 100)}% variance')\n",
    "\n",
    "    \n",
    "    # Plotting diagnostic embeded in a function\n",
    "    colors = {'new': 'red', 'old': 'green', 'restart': 'blue', 'repeat': 'purple'}\n",
    "    latest = 0\n",
    "    current = 0\n",
    "    # post = list(map(np.argmax, sem_readouts['frame_dynamics']['post']))\n",
    "    post = sem_readouts['e_hat']\n",
    "    switch = []\n",
    "    for i in post:\n",
    "        if i != current:\n",
    "            if i > latest:\n",
    "                switch.append('new_post')\n",
    "                latest = i\n",
    "            else:\n",
    "                switch.append('old_post')\n",
    "            current = i\n",
    "        else:\n",
    "            switch.append('current_post')\n",
    "    df = pd.DataFrame(switch, columns=['switch'], index=pred_objhand.index)\n",
    "    ax.vlines(df[df['switch'] == 'new_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to New '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['new'], linestyles='dotted')\n",
    "    ax.vlines(df[df['switch'] == 'old_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to Old '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['old'], linestyles='dotted')\n",
    "    #plt.show()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@pn.depends(frame_slider.param.value,z_checkbox.param.value,run_select.param.value)\n",
    "def flow_plot(frame_slider,z_checkbox,run_select): # start function\n",
    "    # flow_df=pd.read_csv('output/vid/'+run_select+'_kinect_video_features.csv')\n",
    "    df = flow_df.reset_index()\n",
    "    if z_checkbox:\n",
    "        df['pixel_correlation'] = (df['pixel_correlation'] - df['pixel_correlation'].mean())/df['pixel_correlation'].std(ddof=0)\n",
    "    fig,ax = plt.subplots()\n",
    "    df['second'] = df['frame'] / fps\n",
    "    df.plot(kind='line', x='second', y='pixel_correlation', ax=ax)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    plt.title('Interframe Pixel Correlation '+run_select)\n",
    "    ax.get_legend().remove()\n",
    "    #plt.show()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "@pn.depends(frame_slider.param.value,z_checkbox.param.value,run_select.param.value)\n",
    "def flow_plot_post(frame_slider,z_checkbox,run_select): # start function\n",
    "    # flow_df=pd.read_csv('output/vid/'+run_select+'_kinect_video_features.csv')\n",
    "    df = flow_df_post.reset_index()\n",
    "    if z_checkbox:\n",
    "        df['optical_flow_avg'] = (df['optical_flow_avg'] - df['optical_flow_avg'].mean())/df['optical_flow_avg'].std(ddof=0)\n",
    "    fig,ax = plt.subplots()\n",
    "    df['second'] = df['frame'] / fps\n",
    "    df['optical_flow_avg'] = gaussian_filter1d(df['optical_flow_avg'].values, 5)\n",
    "    df.plot(kind='line', x='second', y='optical_flow_avg', ax=ax, alpha=0.5)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    plt.title('Interframe Optical Flow Post '+run_select)\n",
    "    ax.get_legend().remove()\n",
    "    # Plotting diagnostic embeded in a function\n",
    "\n",
    "    colors = {'new': 'red', 'old': 'green', 'restart': 'blue', 'repeat': 'purple'}\n",
    "    latest = 0\n",
    "    current = 0\n",
    "    # post = list(map(np.argmax, sem_readouts['frame_dynamics']['post']))\n",
    "    post = sem_readouts['e_hat']\n",
    "    switch = []\n",
    "    for i in post:\n",
    "        if i != current:\n",
    "            if i > latest:\n",
    "                switch.append('new_post')\n",
    "                latest = i\n",
    "            else:\n",
    "                switch.append('old_post')\n",
    "            current = i\n",
    "        else:\n",
    "            switch.append('current_post')\n",
    "    df = pd.DataFrame(switch, columns=['switch'], index=pred_objhand.index)\n",
    "    ax.vlines(df[df['switch'] == 'new_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to New '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['new'], linestyles='dotted')\n",
    "    ax.vlines(df[df['switch'] == 'old_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to Old '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['old'], linestyles='dotted')\n",
    "    #plt.show()\n",
    "    plt.close(fig)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impose Skeletons and Objects on Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_number(string):\n",
    "    for i in range(100):\n",
    "        string = string.replace(str(i), '')\n",
    "    return string\n",
    "def get_emb_category(category_distances, emb_dim=100):\n",
    "    # Add 1 to avoid 3 objects with 0 distances (rare but might happen), then calculate inversed weights\n",
    "    category_distances = category_distances + 1\n",
    "    # Add 1 to avoid cases there is only one object\n",
    "    category_weights = 1 - category_distances / (category_distances.sum() + 1)\n",
    "    if category_weights.sum() == 0:\n",
    "        logger.error('Sum of probabilities is zero')\n",
    "    average = np.zeros(shape=(1, emb_dim))\n",
    "    for category, prob in category_weights.iteritems():\n",
    "        r = np.zeros(shape=(1, emb_dim))\n",
    "        try:\n",
    "            r += glove_vectors[category]\n",
    "        except Exception as e:\n",
    "            words = category.split(' ')\n",
    "            for w in words:\n",
    "                w = w.replace('(', '').replace(')', '')\n",
    "                r += glove_vectors[w]\n",
    "            r /= len(words)\n",
    "        average += r * prob\n",
    "    return average / category_weights.sum()\n",
    "\n",
    "# sr = objdf.iloc[96].dropna().filter(regex='_dist$').rename(lambda x: remove_number(x).replace('_dist', ''))\n",
    "# arr = get_emb_category(sr, emb_dim=50)\n",
    "# nearest_objects = glove_vectors.most_similar(arr)\n",
    "# nearest_objects = [(nr[0], round(nr[1], 2)) for nr in nearest_objects]\n",
    "# nearest_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def drawskel(frame_number,frame,skel_df,color=(255,0,0),thickness=2):\n",
    "    # frame_number : video frame to select skeleton joints\n",
    "    # frame : image frame to draw on\n",
    "    # skel_df : df of skeleton joint coordinates\n",
    "    # color : RGB tuple for color\n",
    "    # thinkness : thickness to draw bone lines\n",
    "\n",
    "    # Find scale factor of video frame. Original skeleton 2D dimensions are 1080 x 1920\n",
    "    s = frame.shape[0]/1080.0\n",
    "    #ys = frame.shape[1]/1920.0\n",
    "    #xs=1.0\n",
    "    #ys=1.0\n",
    "    r=skel_df[skel_df['frame'] == frame_number]\n",
    "    def seg(bone,f):\n",
    "        # draw segment between two joints\n",
    "        ax = int(r['J'+str(bone[0])+'_2D_X'].values[0] * s)\n",
    "        ay = int(r['J'+str(bone[0])+'_2D_Y'].values[0] * s)\n",
    "        bx = int(r['J'+str(bone[1])+'_2D_X'].values[0] * s)\n",
    "        by = int(r['J'+str(bone[1])+'_2D_Y'].values[0] * s)\n",
    "        #print(ax,ay,bx,by)\n",
    "        if all(x > 0 for x in (ax,ay,bx,by)):\n",
    "            cv2.line(f,(ax,ay),(bx,by),color,thickness)\n",
    "        return f\n",
    "    for bone in [(3,2),(2,20),(20,1),(1,0),\n",
    "                (21,7),(7,6),(22,6),(6,5),(5,4),(4,20),\n",
    "                (20,8),(8,9),(9,10),(24,10),(10,11),(11,23),\n",
    "                (0,12),(12,13),(13,14),(14,15),\n",
    "                (0,16),(16,17),(17,18),(18,19)]:\n",
    "        frame = seg(bone,frame)\n",
    "    # Draw tracked vs inferred joints:\n",
    "    for joint in range(25):\n",
    "        jx = int(r['J'+str(joint)+'_2D_X'].values[0] * s)\n",
    "        jy = int(r['J'+str(joint)+'_2D_Y'].values[0] * s)\n",
    "        jtrack = r['J'+str(joint)+'_Tracked'].values[0]\n",
    "        if (all(x > 0 for x in [jx,jy])):\n",
    "            cv2.circle(frame,(jx,jy),4,color,-1)\n",
    "#             if jtrack=='Tracked':\n",
    "#                 #draw tracked joint\n",
    "#                 cv2.circle(frame,(jx,jy),4,(0,255,0),-1)\n",
    "#             elif jtrack=='Inferred':\n",
    "#                 #draw inferred joint\n",
    "#                 cv2.circle(frame,(jx,jy),4,(0,0,255),-1)\n",
    "#             elif jtrack=='Predicted':\n",
    "#                 cv2.circle(frame,(jx,jy),4,(255,0,0),-1)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def get_nearest(emb_vector: np.ndarray, glove=False):\n",
    "    if glove:\n",
    "        nearest_objects = glove_vectors.most_similar(emb_vector)\n",
    "        nearest_objects = [(nr[0], round(nr[1], 2)) for nr in nearest_objects]\n",
    "        return nearest_objects\n",
    "    \n",
    "    res = {kv[0]: np.linalg.norm(kv[1] - emb_vector) for kv in word2vec.items()}\n",
    "    res = sorted(res.items(), key=lambda kv: kv[1])\n",
    "    res = [(nr[0], round(nr[1], 2)) for nr in res]\n",
    "    return res\n",
    "def drawobj(frame_number,frame,objdf, color=(255,0,0),thickness=1):\n",
    "    odf=objdf[objdf.index==frame_number]\n",
    "    odf=odf[odf.columns[~odf.isna().any()].tolist()]\n",
    "    instances=set([x.split('_')[0] for x in odf.columns])\n",
    "    # TODO: change to 1080 when testing depth\n",
    "    s = frame.shape[0]/1080\n",
    "    for i in instances:\n",
    "        xmin=odf[i+'_x'] * s\n",
    "        ymin=odf[i+'_y'] * s\n",
    "        xmax=xmin+(odf[i+'_w'] * s)\n",
    "        ymax=ymin+(odf[i+'_h'] * s)\n",
    "        try:\n",
    "            conf_score =float(odf[i+'_confidence'])\n",
    "            color = tuple(map(int, np.array(color) * conf_score))\n",
    "        except:\n",
    "            color = (0,0,255)\n",
    "        cv2.rectangle(frame, pt1=(int(xmin), int(ymin)),\n",
    "                      pt2=(int(xmax), int(ymax)),\n",
    "                      color=color, thickness=thickness)\n",
    "        cv2.putText(frame, text=i,\n",
    "                    org=(int(xmin), int(ymax - 5)),\n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=0.4,\n",
    "                    color=color)\n",
    "    # Code to also get nearest objects in Glove for input categories\n",
    "    try:\n",
    "        sr = objdf.loc[frame_number].dropna().filter(regex='_dist$').rename(lambda x: remove_number(x).replace('_dist', ''))\n",
    "        arr = get_emb_category(sr, emb_dim=50)\n",
    "        nearest_objects = get_nearest(arr, glove=True)\n",
    "        for index, instance in enumerate(nearest_objects[:3]):\n",
    "            cv2.putText(frame, text=str(instance), org=(frame.shape[1]-420, 20 + 20*index),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.4,\n",
    "                        color=(255, 0, 0))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return frame\n",
    "\n",
    "def drawobj_z(frame_number,frame,objdf_z, color=(255,0,0),thickness=1):\n",
    "    odf=objdf_z[objdf_z.index==frame_number]\n",
    "    odf=odf[odf.columns[~odf.isna().any()].tolist()]\n",
    "    instances=set([x.split('_')[0] for x in odf.columns])\n",
    "    s = frame.shape[0]/1080.0\n",
    "    for i in instances:\n",
    "        xmin=odf[i+'_x'] * s\n",
    "        ymin=odf[i+'_y'] * s\n",
    "        xmax=xmin+(odf[i+'_w'] * s)\n",
    "        ymax=ymin+(odf[i+'_h'] * s)\n",
    "        try:\n",
    "            conf_score =float(odf[i+'_confidence'])\n",
    "            color = tuple(map(int, np.array(color) * conf_score))\n",
    "        except:\n",
    "            color = (0,0,255)\n",
    "        cv2.rectangle(frame, pt1=(int(xmin), int(ymin)),\n",
    "                      pt2=(int(xmax), int(ymax)),\n",
    "                      color=color, thickness=thickness)\n",
    "        cv2.putText(frame, text=i,\n",
    "                    org=(int(xmin), int(ymax - 5)),\n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=0.4,\n",
    "                    color=color)\n",
    "\n",
    "    return frame\n",
    "\n",
    "@pn.depends(frame_slider.param.value,skel_checkbox.param.value,obj_checkbox.param.value,run_select.param.value)\n",
    "def draw_frame_resampled(frame_slider, skel_checkbox, obj_checkbox,run_select, get_img=False):\n",
    "    outframe = deepcopy(anchored_frames[frame_slider])\n",
    "#     outframe_z = deepcopy(outframe)\n",
    "    # draw skeleton here\n",
    "    if skel_checkbox:\n",
    "        try:\n",
    "            \n",
    "            # outframe = drawskel(frame_slider,outframe,skel_df)\n",
    "            outframe = drawskel(frame_slider,outframe,pca_input_df,color=(255, 0, 0))\n",
    "            # TODO: comment this line if not using position in training SEM.\n",
    "            outframe = drawskel(frame_slider,outframe,pred_skel_df,color=(0, 255, 0))\n",
    "        except:\n",
    "            cv2.putText(outframe,'No skeleton data',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2)\n",
    "    else:\n",
    "        outframe = anchored_frames[frame_slider]\n",
    "    if obj_checkbox:\n",
    "        try:\n",
    "            # Draw ground truth objects\n",
    "            outframe = drawobj(frame_slider, outframe, objdf)\n",
    "            # TODO: uncomment to test depth with two distinct frames\n",
    "#             outframe_z = drawobj_z(frame_slider, outframe_z, objdf_z, color=(0, 255, 0))\n",
    "            # This to draw nearest objects in the same frame\n",
    "            outframe = drawobj_z(frame_slider, outframe, objdf_z, color=(0, 255, 0))\n",
    "            # Draw nearest objects (in the video)\n",
    "            nearest_objects = get_nearest(pred_objhand.loc[frame_slider, :].values)\n",
    "            for index, instance in enumerate(nearest_objects[:3]):\n",
    "                cv2.putText(outframe, text=str(instance), org=(outframe.shape[1]-140, 20 + 20*index),\n",
    "                            fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.4,\n",
    "                            color=(0, 255, 0))\n",
    "            # Draw nearest objects (Glove corpus)\n",
    "    #         glove_nearest_objects = glove_vectors.most_similar([np.array(pred_objhand.loc[frame_slider, :].values, dtype=np.float32)])\n",
    "    #         glove_nearest_objects = [obj_score[0] for obj_score in glove_nearest_objects]\n",
    "            glove_nearest_objects = get_nearest([np.array(pred_objhand.loc[frame_slider, :].values, dtype=np.float32)], glove=True)\n",
    "            for index, instance in enumerate(glove_nearest_objects[:3]):\n",
    "                cv2.putText(outframe, text=str(instance), org=(outframe.shape[1]-280, 20 + 20*index),\n",
    "                            fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.4,\n",
    "                            color=(0, 255, 255))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    # add frameID\n",
    "    cv2.putText(outframe, text=f'FrameID: {frame_slider}', org=(10, 100),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.4,\n",
    "        color=(0, 255, 0))\n",
    "    \n",
    "    # add Segmentation flag\n",
    "    index = pred_objhand.index.get_indexer([frame_slider])[0]\n",
    "    if sem_readouts['e_hat'][index] != sem_readouts['e_hat'][index - 1]:\n",
    "\n",
    "        cv2.putText(outframe, text='SEGMENT', org=(10, 120),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.4,\n",
    "            color=(0, 255, 0))\n",
    "    \n",
    "    if get_img:\n",
    "        return outframe\n",
    "    \n",
    "    # embedding image on axis to align \n",
    "    # TODO: uncomment to test depth with two distinct frames\n",
    "#     fig,ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "#     ax[0].imshow(cv2.cvtColor(outframe, cv2.COLOR_BGR2RGB))\n",
    "#     ax[1].imshow(cv2.cvtColor(outframe_z, cv2.COLOR_BGR2RGB))\n",
    "    fig,ax = plt.subplots(nrows=1, ncols=1)\n",
    "    ax.imshow(cv2.cvtColor(outframe, cv2.COLOR_BGR2RGB))\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM DIAGNOSTIC READOUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def impose_rainbow_events(ax, fig):\n",
    "    cm = plt.get_cmap('gist_rainbow')\n",
    "    post = sem_readouts['e_hat']\n",
    "    boundaries = sem_readouts['boundaries']\n",
    "    NUM_COLORS = post.max()\n",
    "    # Hard-code 40 events for rainbow to be able to compare across epochs\n",
    "    # NUM_COLORS = 30\n",
    "    for i, (b, e) in enumerate(zip(boundaries, post)):\n",
    "        if b != 0:\n",
    "            second = i / frame_interval + offset\n",
    "            if b == 1:\n",
    "                ax.axvline(second, linestyle=(0, (5, 10)), alpha=0.3, color=cm(1. * e / NUM_COLORS), label='Old Event')\n",
    "            elif b == 2:\n",
    "                ax.axvline(second, linestyle='solid', alpha=0.3, color=cm(1. * e / NUM_COLORS), label='New Event')\n",
    "            elif b == 3:\n",
    "                ax.axvline(second, linestyle='dotted', alpha=0.3, color=cm(1. * e / NUM_COLORS), label='Restart Event')\n",
    "    fig.colorbar(matplotlib.cm.ScalarMappable(cmap=cm, norm=matplotlib.colors.Normalize(vmin=0, vmax=NUM_COLORS, clip=False)),\n",
    "                 orientation='horizontal')\n",
    "\n",
    "\n",
    "def impose_metrics(ax, fig):\n",
    "    pred_boundaries = get_binned_prediction(sem_readouts['post'], second_interval=second_interval,\n",
    "                                            sample_per_second=3)\n",
    "    # Padding prediction boundaries, could be changed to have higher resolution but not necessary\n",
    "    pred_boundaries = np.hstack([[0] * round(first_frame / fps / second_interval), pred_boundaries]).astype(bool)\n",
    "    #     gt_freqs_local = gaussian_filter1d(gt_freqs, 2)\n",
    "    last = min(len(pred_boundaries), len(gt_freqs))\n",
    "    bicorr = get_point_biserial(pred_boundaries[:last], gt_freqs[:last])\n",
    "    pred_boundaries_gaussed = gaussian_filter1d(pred_boundaries.astype(float), 1)\n",
    "    pearson_r, p = stats.pearsonr(pred_boundaries_gaussed[:last], gt_freqs[:last])\n",
    "    ax.text(0.1, 0.3, f'bicorr={bicorr:.3f}, pearson={pearson_r:.3f}', fontsize=14)\n",
    "    ax.set_ylim([0, 0.4])\n",
    "\n",
    "\n",
    "def impose_line_boundaries(ax, fig):\n",
    "    from matplotlib.lines import Line2D\n",
    "    linestyles = ['dashed', 'solid', 'dotted']\n",
    "    lines = [Line2D([0], [0], color='black', linewidth=1, linestyle=ls) for ls in linestyles]\n",
    "    labels = ['Old Event', 'New Event', 'Restart Event']\n",
    "    ax.legend(lines, labels, loc='upper right')\n",
    "\n",
    "    \n",
    "@pn.depends(frame_slider.param.value, run_select.param.value)\n",
    "def plot_diagnostic_readouts(frame_slider, run_select, title='', get_img=False):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(gaussian_filter1d(gt_freqs, 1), label='Subject Boundaries')\n",
    "    ax.set_xlabel('Time (second)')\n",
    "    ax.set_ylabel('Boundary Probability')\n",
    "    ax.set_title('Diagnostic Readouts ' + run_select)\n",
    "    colors = {'new': 'red', 'old': 'green', 'restart': 'blue', 'repeat': 'purple'}\n",
    "\n",
    "    impose_rainbow_events(ax, fig)\n",
    "    impose_line_boundaries(ax, fig)\n",
    "    impose_metrics(ax, fig)\n",
    "\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    if get_img:\n",
    "        from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "        #         canvas = FigureCanvas(fig)\n",
    "        #         canvas.draw()\n",
    "        fig.canvas.draw()\n",
    "        image_from_plot = cv2.cvtColor(np.asarray(fig.canvas.buffer_rgba()), cv2.COLOR_RGBA2BGR)\n",
    "        plt.close(fig)\n",
    "        return image_from_plot\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "@pn.depends(frame_slider.param.value, run_select.param.value)\n",
    "def plot_likelihood(frame_slider, run_select):\n",
    "\n",
    "    sem_readouts['frame_dynamics']['old_lik'] = list(map(np.max, sem_readouts['frame_dynamics']['old_lik']))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    df = pd.DataFrame(sem_readouts['frame_dynamics'], index=inputdf[0].index[1:])\n",
    "    df['second'] = df.index / fps\n",
    "    df.plot(kind='line', x='second', y='new_lik',alpha=1.00,ax=ax)\n",
    "    df.plot(kind='line', x='second', y='old_lik',alpha=1.00,ax=ax)\n",
    "    df.plot(kind='line', x='second', y='repeat_lik',alpha=1.00,ax=ax)\n",
    "    df.plot(kind='line', x='second', y='restart_lik',alpha=1.00,ax=ax)\n",
    "\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend()\n",
    "    ax.set_title('Likelihood '+run_select)\n",
    "    ax.set_ylabel('Log-likelihood')\n",
    "    ax.set_xlabel('Time (second)')\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "\n",
    "@pn.depends(frame_slider.param.value, run_select.param.value)\n",
    "def plot_prior(frame_slider, run_select):\n",
    "\n",
    "    sem_readouts['frame_dynamics']['old_prior'] = list(map(np.max, sem_readouts['frame_dynamics']['old_prior']))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    df = pd.DataFrame(sem_readouts['frame_dynamics'], index=inputdf[0].index[1:])\n",
    "    df['second'] = df.index / fps\n",
    "    df.plot(kind='line', x='second', y='new_prior',alpha=1.00,ax=ax)\n",
    "    df.plot(kind='line', x='second', y='old_prior',alpha=1.00,ax=ax)\n",
    "    df.plot(kind='line', x='second', y='repeat_prior',alpha=1.00,ax=ax)\n",
    "    df.plot(kind='line', x='second', y='restart_prior',alpha=1.00,ax=ax)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend()\n",
    "    ax.set_title('Prior '+run_select)\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "@pn.depends(frame_slider.param.value, run_select.param.value)\n",
    "def plot_pe(frame_slider, run_select):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    df = pd.DataFrame({'pe':sem_readouts['pe']}, index=inputdf[0].index)\n",
    "    df['second'] = df.index / fps\n",
    "    df.plot(kind='line', x='second', y='pe',alpha=1.00,ax=ax)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    #ax.set_ylim([-3, 3])\n",
    "    #ax.legend()\n",
    "    ax.set_title('Prediction Error '+run_select)\n",
    "    # Plotting diagnostic embeded in a function\n",
    "    colors = {'new': 'red', 'old': 'green', 'restart': 'blue', 'repeat': 'purple'}\n",
    "    latest = 0\n",
    "    current = 0\n",
    "    # post = list(map(np.argmax, sem_readouts['frame_dynamics']['post']))\n",
    "    post = sem_readouts['e_hat']\n",
    "    switch = []\n",
    "    for i in post:\n",
    "        if i != current:\n",
    "            if i > latest:\n",
    "                switch.append('new_post')\n",
    "                latest = i\n",
    "            else:\n",
    "                switch.append('old_post')\n",
    "            current = i\n",
    "        else:\n",
    "            switch.append('current_post')\n",
    "    df = pd.DataFrame(switch, columns=['switch'], index=pred_objhand.index)\n",
    "    ax.vlines(df[df['switch'] == 'new_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to New '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['new'], linestyles='dotted')\n",
    "    ax.vlines(df[df['switch'] == 'old_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to Old '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['old'], linestyles='dotted')\n",
    "    ax.get_legend().remove()\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "@pn.depends(frame_slider.param.value, run_select.param.value)\n",
    "def plot_surprise(frame_slider, run_select):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    df = pd.DataFrame({'surprise':sem_readouts['surprise']}, index=inputdf[0].index)\n",
    "    df['second'] = df.index / fps\n",
    "    df.plot(kind='line', x='second', y='surprise',alpha=1.00,ax=ax)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    ax.set_title('Bayesian Surprise '+run_select)\n",
    "    # Plotting diagnostic embeded in a function\n",
    "    colors = {'new': 'red', 'old': 'green', 'restart': 'blue', 'repeat': 'purple'}\n",
    "    latest = 0\n",
    "    current = 0\n",
    "    post = sem_readouts['e_hat']\n",
    "    switch = []\n",
    "    for i in post:\n",
    "        if i != current:\n",
    "            if i > latest:\n",
    "                switch.append('new_post')\n",
    "                latest = i\n",
    "            else:\n",
    "                switch.append('old_post')\n",
    "            current = i\n",
    "        else:\n",
    "            switch.append('current_post')\n",
    "    df = pd.DataFrame(switch, columns=['switch'], index=pred_objhand.index)\n",
    "    ax.vlines(df[df['switch'] == 'new_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to New '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['new'], linestyles='dotted')\n",
    "    ax.vlines(df[df['switch'] == 'old_post'].index / fps, ymin=0, ymax=1, transform=ax.get_xaxis_transform(),alpha=0.5, label='Switch to Old '\n",
    "                                                                                                               'Event',\n",
    "              color=colors['old'], linestyles='dotted')\n",
    "    ax.get_legend().remove()\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "@pn.depends(frame_slider.param.value, run_select.param.value)\n",
    "def plot_posterior(frame_slider, run_select):\n",
    "    fig, ax = plt.subplots()\n",
    "    df = pd.DataFrame(sem_readouts['post'], index=inputdf[0].index)\n",
    "#     df =df.loc[:, (df != 0).any(axis=0)]\n",
    "    df =df.loc[:, (df > 1e-2).any(axis=0)]\n",
    "    df.index = df.index / fps\n",
    "    df.index.names = ['second']\n",
    "    NUM_COLORS = len(df.columns)\n",
    "    cm = plt.get_cmap('gist_rainbow')\n",
    "    ax.set_prop_cycle(color=[cm(1.*i/NUM_COLORS) for i in range(NUM_COLORS)])\n",
    "    df.plot.area(ax=ax, stacked=False)\n",
    "    ax.axvline(frame_slider / fps, linewidth=2, alpha=0.5, color='r')\n",
    "    ax.set_title('Posterior Probability '+run_select)\n",
    "    ax.get_legend().remove()\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard Arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/run_sem/mar_20_individual_depth_scene/1.1.1_kinect_trimmar_20_individual_depth_scene_gtfreqs.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-62f27075ba69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m dashboard = pn.Column(\n\u001b[0;32m      2\u001b[0m     \u001b[0mpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_select\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlisten_to_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_slider\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_slider\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskel_checkbox\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobj_checkbox\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz_checkbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     pn.Row(pn.Column(flow_plot_post, objhand_plot, skel_plot_post_euclid), \n",
      "\u001b[1;32m~\\anaconda3\\envs\\pt-tf-37\\lib\\site-packages\\panel\\layout\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *objects, **params)\u001b[0m\n\u001b[0;32m    358\u001b[0m                                  \u001b[1;34m\"as positional arguments or as a keyword, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m                                  \"not both.\" % type(self).__name__)\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpanel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpane\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpane\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;34m'objects'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpanel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpane\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpane\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pt-tf-37\\lib\\site-packages\\panel\\layout\\base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    358\u001b[0m                                  \u001b[1;34m\"as positional arguments or as a keyword, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m                                  \"not both.\" % type(self).__name__)\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpanel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpane\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpane\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;34m'objects'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpanel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpane\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpane\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pt-tf-37\\lib\\site-packages\\panel\\pane\\base.py\u001b[0m in \u001b[0;36mpanel\u001b[1;34m(obj, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mpane\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPaneBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_pane_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpane\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpane\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpane\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pt-tf-37\\lib\\site-packages\\panel\\param.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, object, **params)\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_inner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pt-tf-37\\lib\\site-packages\\panel\\param.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, function)\u001b[0m\n\u001b[0;32m    654\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marg_deps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkw_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_pane\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pt-tf-37\\lib\\site-packages\\param\\parameterized.py\u001b[0m in \u001b[0;36m_depends\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_depends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[0mdeps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-c337632d1b3b>\u001b[0m in \u001b[0;36mlisten_to_run\u001b[1;34m(run_select)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0manchored_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'output/run_sem/frames/{run_select}_kinect_trimjan_27_pca_frames.joblib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# This data is for plotting diagnostic results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mgt_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'output/run_sem/{tag}/{run_select}_kinect_trim{tag}_gtfreqs.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0msem_readouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'output/run_sem/{tag}/{run_select}_kinect_trim{tag}_diagnostic{epoch}.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Preprocess likelihoods because old_lik contains new likelihoods and repeat likelihoods as well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/run_sem/mar_20_individual_depth_scene/1.1.1_kinect_trimmar_20_individual_depth_scene_gtfreqs.pkl'"
     ]
    }
   ],
   "source": [
    "dashboard = pn.Column(\n",
    "    pn.Row(title),\n",
    "    pn.Row(run_select, listen_to_run),\n",
    "    pn.Row(pn.Column(frame_slider, second_slider,text_input), pn.Column(skel_checkbox,obj_checkbox,z_checkbox)),\n",
    "    pn.Row(pn.Column(flow_plot_post, objhand_plot, skel_plot_post_euclid), \n",
    "           pn.Column(draw_frame_resampled,plot_posterior, plot_likelihood),\n",
    "          pn.Column(plot_pe, plot_diagnostic_readouts, plot_surprise))\n",
    ")\n",
    "\n",
    "# Launch the dashboard\n",
    "dashboard.servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# # Start with one\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.plot([1,2,3])\n",
    "\n",
    "# # Now later you get a new subplot; change the geometry of the existing\n",
    "# n = len(fig.axes)\n",
    "# for i in range(n):\n",
    "#     fig.axes[i].change_geometry(n+1, 1, i+1)\n",
    "\n",
    "# # Add the new\n",
    "# ax = fig.add_subplot(n+1, 1, n+1)\n",
    "# ax.plot([4,5,6])\n",
    "\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_button = pn.widgets.Button(name='Draw the video', button_type='primary')\n",
    "# from tqdm.notebook import tqdm\n",
    "# def draw_video(video_button):\n",
    "#     output_video_path = f'output/videos/{run_select.value}_{tag}_{epoch}.avi'\n",
    "#     if not os.path.exists(f'output/videos'):\n",
    "#         os.makedirs('output/videos')\n",
    "#     if os.path.exists(output_video_path):\n",
    "#         print('Video already drawn!!!')\n",
    "#         return\n",
    "    \n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#     cv2_writer = cv2.VideoWriter(output_video_path, fourcc=fourcc, fps=15,\n",
    "#                                       frameSize=(640, 960), isColor=True)\n",
    "#     for frame_id, frame in tqdm(anchored_frames.items()):\n",
    "#         img = draw_frame_resampled(frame_id, skel_checkbox=True, obj_checkbox=True, run_select=run_select.value, get_img=True)\n",
    "#         img = cv2.resize(img, dsize=(640, 480))\n",
    "#         diagnostic = plot_diagnostic_readouts(frame_id, run_select.value, title='', get_img=True)\n",
    "#         diagnostic = cv2.resize(diagnostic, dsize=(640, 480))\n",
    "#         concat = np.concatenate([img, diagnostic], axis=0)\n",
    "#         cv2_writer.write(concat)\n",
    "#     cv2_writer.release()\n",
    "#     print(f'Done {output_video_path}')\n",
    "    \n",
    "\n",
    "# video_button.on_click(draw_video)\n",
    "# video_button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with biserial and pearson_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import scipy.stats as stats\n",
    "\n",
    "# # gt_freqs = pkl.load(open('output/run_sem/{tag}/2.2.3_kinect_trimfeb_27_like_21_replicate_gtfreqs.pkl', 'rb'))\n",
    "# # sem_readouts = pkl.load(open('output/run_sem/{tag}/2.2.3_kinect_trimfeb_27_like_21_replicate_diagnostic_0.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_point_biserial(boundaries_binned, binned_comp) -> float:\n",
    "#     M_1 = np.mean(binned_comp[boundaries_binned != 0])\n",
    "#     M_0 = np.mean(binned_comp[boundaries_binned == 0])\n",
    "\n",
    "#     n_1 = np.sum(boundaries_binned != 0)\n",
    "#     n_0 = np.sum(boundaries_binned == 0)\n",
    "#     n = n_1 + n_0\n",
    "\n",
    "#     s = np.std(binned_comp)\n",
    "#     r_pb = (M_1 - M_0) / s * np.sqrt(n_1 * n_0 / (float(n) ** 2))\n",
    "#     return r_pb\n",
    "# pred_boundaries = get_binned_prediction(sem_readouts['post'], second_interval=second_interval,\n",
    "#                                         sample_per_second=3)\n",
    "# # Padding prediction boundaries, could be changed to have higher resolution but not necessary\n",
    "# pred_boundaries = np.hstack([[0] * round(first_frame / fps / second_interval), pred_boundaries]).astype(bool)\n",
    "# # gt_freqs_local = gaussian_filter1d(gt_freqs, 2)\n",
    "# last = min(len(pred_boundaries), len(gt_freqs))\n",
    "# bicorr = get_point_biserial(pred_boundaries[:last].astype(int), gt_freqs[:last])\n",
    "# bicorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r, p = stats.pearsonr(pred_boundaries[:last].astype(int), gt_freqs[:last])\n",
    "# r, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boundaries_gaussed = gaussian_filter1d(pred_boundaries.astype(float), 1)\n",
    "# r, p = stats.pearsonr(pred_boundaries_gaussed[:last], gt_freqs[:last])\n",
    "# r, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 2, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boundaries_tinker = pred_boundaries.copy()\n",
    "# pred_boundaries_tinker[:200] = 0\n",
    "# pred_boundaries_tinker[200:] = 0\n",
    "# print(np.where(pred_boundaries_tinker != 0))\n",
    "# pred_boundaries_tinker[[182]] = 1\n",
    "# r, p = stats.pearsonr(pred_boundaries_tinker[:last], gt_freqs[:last])\n",
    "# r, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boundaries_tinker_gaussed = gaussian_filter1d(pred_boundaries_tinker.astype(float), 1)\n",
    "# r_blurred, p = stats.pearsonr(pred_boundaries_tinker_gaussed[:last], gt_freqs[:last])\n",
    "# r_blurred, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axs[0][0].plot(gt_freqs, label='Subjects')\n",
    "# # axs[0][0].plot(pred_boundaries_tinker, label='Model')\n",
    "# axs[0][0].vlines(np.where(pred_boundaries_tinker != 0)[0], ymin=0, ymax=1, alpha=0.5, label='Model', linestyles='dotted')\n",
    "# axs[0][0].plot(pred_boundaries_tinker_gaussed, label='Gauss', alpha=0.3)\n",
    "# axs[0][0].text(0.1, 0.8, f'bicorr={r:.3f}, pearson_r={r_blurred:.3f}')\n",
    "# axs[0][0].set_ylim()\n",
    "# axs[0][0].legend()\n",
    "# # fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(gt_freqs, label='Subjects')\n",
    "# # plt.plot(pred_boundaries_tinker, label='Model')\n",
    "# plt.vlines(np.where(pred_boundaries_tinker != 0)[0], ymin=0, ymax=1, alpha=0.5, label='Model', linestyles='dotted')\n",
    "# plt.plot(pred_boundaries_tinker_gaussed, label='Gauss', alpha=0.3)\n",
    "# plt.text(0.1, 0.8, f'bicorr={r:.3f}, pearson_r={r_blurred:.3f}')\n",
    "# plt.ylim()\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boundaries_tinker = pred_boundaries.copy()\n",
    "# pred_boundaries_tinker[:150] = 0\n",
    "# pred_boundaries_tinker[200:] = 0\n",
    "# print(np.where(pred_boundaries_tinker != 0))\n",
    "# # pred_boundaries_tinker[[165, 179]] = 1\n",
    "# r, p = stats.pearsonr(pred_boundaries_tinker[:last], gt_freqs[:last])\n",
    "# r, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boundaries_tinker_gaussed = gaussian_filter1d(pred_boundaries_tinker.astype(float), 1)\n",
    "# r_blurred, p = stats.pearsonr(pred_boundaries_tinker_gaussed[:last], gt_freqs[:last])\n",
    "# r_blurred, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(gt_freqs, label='Subjects')\n",
    "# # plt.plot(pred_boundaries_tinker, label='Model')\n",
    "# plt.vlines(np.where(pred_boundaries_tinker != 0)[0], ymin=0, ymax=1, alpha=0.5, label='Model', linestyles='dotted')\n",
    "# plt.plot(pred_boundaries_tinker_gaussed, label='Gauss', alpha=0.3)\n",
    "# plt.text(0.1, 0.8, f'bicorr={r:.3f}, pearson_r={r_blurred:.3f}')\n",
    "# plt.ylim()\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axs[0][1].plot(gt_freqs, label='Subjects')\n",
    "# # ax[0][1].plot(pred_boundaries_tinker, label='Model')\n",
    "# axs[0][1].vlines(np.where(pred_boundaries_tinker != 0)[0], ymin=0, ymax=1, alpha=0.5, label='Model', linestyles='dotted')\n",
    "# axs[0][1].plot(pred_boundaries_tinker_gaussed, label='Gauss', alpha=0.3)\n",
    "# axs[0][1].text(0.1, 0.8, f'bicorr={r:.3f}, pearson_r={r_blurred:.3f}')\n",
    "# axs[0][1].set_ylim()\n",
    "# axs[0][1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boundaries_tinker = pred_boundaries.copy()\n",
    "# pred_boundaries_tinker[:90] = 0\n",
    "# pred_boundaries_tinker[98:] = 0\n",
    "# print(np.where(pred_boundaries_tinker != 0))\n",
    "# pred_boundaries_tinker[87:94] = 1\n",
    "# r, p = stats.pearsonr(pred_boundaries_tinker[:last], gt_freqs[:last])\n",
    "# r, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boundaries_tinker_gaussed = gaussian_filter1d(pred_boundaries_tinker.astype(float), 1)\n",
    "# r_blurred, p = stats.pearsonr(pred_boundaries_tinker_gaussed[:last], gt_freqs[:last])\n",
    "# r_blurred, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axs[1][1].plot(gt_freqs, label='Subjects')\n",
    "# # axs[1][1].plot(pred_boundaries_tinker, label='Model')\n",
    "# axs[1][1].vlines(np.where(pred_boundaries_tinker != 0)[0], ymin=0, ymax=1, alpha=0.5, label='Model', linestyles='dotted')\n",
    "# axs[1][1].plot(pred_boundaries_tinker_gaussed, label='Gauss', alpha=0.3)\n",
    "# axs[1][1].text(0.1, 0.8, f'bicorr={r:.3f}, pearson_r={r_blurred:.3f}')\n",
    "# axs[1][1].set_ylim()\n",
    "# axs[1][1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boundaries_tinker = pred_boundaries.copy()\n",
    "# pred_boundaries_tinker[:100] = 0\n",
    "# pred_boundaries_tinker[100:] = 0\n",
    "# print(np.where(pred_boundaries_tinker != 0))\n",
    "# pred_boundaries_tinker[90] = 1\n",
    "# r, p = stats.pearsonr(pred_boundaries_tinker[:last], gt_freqs[:last])\n",
    "# r, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boundaries_tinker_gaussed = gaussian_filter1d(pred_boundaries_tinker.astype(float), 1)\n",
    "# r_blurred, p = stats.pearsonr(pred_boundaries_tinker_gaussed[:last], gt_freqs[:last])\n",
    "# r_blurred, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axs[1][0].plot(gt_freqs, label='Subjects')\n",
    "# # axs[1][1].plot(pred_boundaries_tinker, label='Model')\n",
    "# axs[1][0].vlines(np.where(pred_boundaries_tinker != 0)[0], ymin=0, ymax=1, alpha=0.5, label='Model', linestyles='dotted')\n",
    "# axs[1][0].plot(pred_boundaries_tinker_gaussed, label='Gauss', alpha=0.3)\n",
    "# axs[1][0].text(0.1, 0.8, f'bicorr={r:.3f}, pearson_r={r_blurred:.3f}')\n",
    "# axs[1][0].set_ylim()\n",
    "# axs[1][0].legend()\n",
    "# fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tinker with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# import pickle as pkl\n",
    "# from utils import get_point_biserial\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy.stats as stats\n",
    "# from scipy.ndimage import gaussian_filter1d\n",
    "# %matplotlib inline\n",
    "\n",
    "# gt_freqs = pkl.load(open('output/run_sem/{tag}/1.1.8_kinect_trimfeb_17_vw300_lmda1e10_df100_gtfreqs.pkl', 'rb'))\n",
    "\n",
    "# sorted_indices = np.argsort(gt_freqs)\n",
    "\n",
    "# bicorrs = []\n",
    "# pearsons = []\n",
    "# pearsons_random = []\n",
    "# for i in range(1, sorted_indices.shape[0]):\n",
    "#     dummy = np.zeros(shape=(745,))\n",
    "#     dummy[sorted_indices[-i:]] = 1\n",
    "#     dummy_gaussian = gaussian_filter1d(dummy.astype(float), 1)\n",
    "#     bicorrs.append(get_point_biserial(dummy, gt_freqs))\n",
    "#     r_blurred, p = stats.pearsonr(dummy_gaussian, gt_freqs)\n",
    "#     pearsons.append(r_blurred)\n",
    "    \n",
    "#     dummy = np.zeros(shape=(745,))\n",
    "#     dummy[np.random.choice(745, i)] = 1\n",
    "#     dummy[sorted_indices[-i:]] = 1\n",
    "#     dummy_gaussian = gaussian_filter1d(dummy.astype(float), 1)\n",
    "#     r_blurred_random, p = stats.pearsonr(dummy_gaussian, gt_freqs)\n",
    "#     pearsons_random.append(r_blurred_random)\n",
    "# plt.plot(pearsons_random, label='Ideal + Random')\n",
    "# plt.plot(pearsons, label='Ideal')\n",
    "# plt.xlabel('# Boundaries')\n",
    "# plt.ylabel('Pearson Correlation')\n",
    "# plt.title('Ideal Pearson Correlation for each #Boundary - 1.1.8')\n",
    "# plt.legend()\n",
    "# plt.savefig('Pearson_boundary.png')\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_objhand.index.get_indexer([1402])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard Testing before Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dashboard = pn.Column(\n",
    "#     pn.Row(title),\n",
    "#     pn.Row(run_select, listen_to_run),\n",
    "#     pn.Row(pn.Column(frame_slider, second_slider,text_input), pn.Column(skel_checkbox,obj_checkbox,z_checkbox)),\n",
    "#            pn.Column(draw_frame_resampled)\n",
    "# )\n",
    "\n",
    "# # Launch the dashboard\n",
    "# dashboard.servable()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
